import { randomUUID } from 'node:crypto'
import { sql } from 'drizzle-orm'
import type { PostgresJsDatabase } from 'drizzle-orm/postgres-js'
import { drizzle } from 'drizzle-orm/postgres-js'
import postgres from 'postgres'
import { TestEnvironment } from './test-environment.js'

export interface TestContext {
  db: PostgresJsDatabase
  client: postgres.Sql
  cleanup: () => Promise<void>
}

export interface ParallelTestContext extends TestContext {
  schemaName: string
}

/**
 * çµ±åˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
 * Sequentialï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ï¼‰ã¨Parallelï¼ˆã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹ï¼‰ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
 */
export class TestDatabaseSetup {
  private static instance: TestDatabaseSetup
  private testEnv!: TestEnvironment
  private masterClient!: postgres.Sql
  private masterDb!: PostgresJsDatabase
  private initialized = false
  private activeSchemas = new Set<string>()
  private migrationsRun = false

  private constructor() {}

  static async getInstance(): Promise<TestDatabaseSetup> {
    if (!TestDatabaseSetup.instance) {
      TestDatabaseSetup.instance = new TestDatabaseSetup()
      await TestDatabaseSetup.instance.initialize()
    }
    // ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã”ã¨ã«ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    TestDatabaseSetup.instance.migrationsRun = false
    return TestDatabaseSetup.instance
  }

  private async initialize(): Promise<void> {
    if (this.initialized) return

    this.testEnv = await TestEnvironment.getInstance()
    const connectionString = this.testEnv.getPostgresConnectionString()

    this.masterClient = postgres(connectionString, {
      max: 50, // ä¸¦åˆ—å®Ÿè¡Œã®ãŸã‚ã®ååˆ†ãªã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³æ•°
      onnotice: () => {},
    })
    this.masterDb = drizzle(this.masterClient)

    this.initialized = true
  }

  /**
   * publicã‚¹ã‚­ãƒ¼ãƒã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆä¸€åº¦ã ã‘ï¼‰
   */
  async runMigrationsOnce(): Promise<void> {
    if (this.migrationsRun) return

    console.log('ğŸ”„ Running migrations once on public schema...')

    try {
      // ã¾ãšæ—¢å­˜ã®å‹ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤ï¼ˆCASCADEä»˜ãã§ä¾å­˜é–¢ä¿‚ã‚‚å«ã‚ã¦å‰Šé™¤ï¼‰
      const cleanupStatements = [
        // ä¾å­˜é–¢ä¿‚ã®ã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…ˆã«å‰Šé™¤
        'DROP TABLE IF EXISTS public.download_logs CASCADE',
        'DROP TABLE IF EXISTS public.share_links CASCADE',
        'DROP TABLE IF EXISTS public.attachments CASCADE',
        'DROP TABLE IF EXISTS public.auth_audit_logs CASCADE',
        'DROP TABLE IF EXISTS public.booking_reservations CASCADE',
        'DROP TABLE IF EXISTS public.bookings CASCADE',
        'DROP TABLE IF EXISTS public.email_verification_tokens CASCADE',
        'DROP TABLE IF EXISTS public.failed_login_attempts CASCADE',
        'DROP TABLE IF EXISTS public.opening_hours CASCADE',
        'DROP TABLE IF EXISTS public.password_reset_tokens CASCADE',
        'DROP TABLE IF EXISTS public.reservations CASCADE',
        'DROP TABLE IF EXISTS public.reviews CASCADE',
        'DROP TABLE IF EXISTS public.services CASCADE',
        'DROP TABLE IF EXISTS public.service_categories CASCADE',
        'DROP TABLE IF EXISTS public.sessions CASCADE',
        'DROP TABLE IF EXISTS public.staff_working_hours CASCADE',
        'DROP TABLE IF EXISTS public.staff CASCADE',
        'DROP TABLE IF EXISTS public.trusted_ip_addresses CASCADE',
        'DROP TABLE IF EXISTS public.user_2fa_secrets CASCADE',
        'DROP TABLE IF EXISTS public.user_sessions CASCADE',
        'DROP TABLE IF EXISTS public.users CASCADE',
        'DROP TABLE IF EXISTS public.customers CASCADE',
        'DROP TABLE IF EXISTS public.salons CASCADE',
        // å‹ã‚’å‰Šé™¤
        'DROP TYPE IF EXISTS public.booking_status CASCADE',
        'DROP TYPE IF EXISTS public.day_of_week CASCADE',
        'DROP TYPE IF EXISTS public.file_type CASCADE',
        'DROP TYPE IF EXISTS public.reservation_status CASCADE',
        'DROP TYPE IF EXISTS public.service_category CASCADE',
        'DROP TYPE IF EXISTS public.two_factor_status CASCADE',
        'DROP TYPE IF EXISTS public.user_account_status CASCADE',
        'DROP TYPE IF EXISTS public.user_role CASCADE',
      ]

      for (const stmt of cleanupStatements) {
        try {
          await this.masterDb.execute(sql.raw(stmt))
        } catch (_error) {
          // ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        }
      }

      // infrastructureãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸmigrationãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ
      const migrationFiles = ['20250724_000001_initial_schema.sql']

      const basePath = new URL(
        '../../../../apps/migration/scripts/',
        import.meta.url
      ).pathname

      for (const file of migrationFiles) {
        try {
          const { readFileSync } = await import('node:fs')
          const migrationContent = readFileSync(`${basePath}${file}`, 'utf-8')

          // Split by --> statement-breakpoint and execute each statement
          const statements = migrationContent.split('--> statement-breakpoint')

          for (const statement of statements) {
            const trimmedStatement = statement.trim()
            if (trimmedStatement) {
              try {
                await this.masterDb.execute(sql.raw(trimmedStatement))
              } catch (error) {
                const errorMessage =
                  error instanceof Error ? error.message : String(error)
                // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯è©³ç´°ã‚’å‡ºåŠ›
                console.error(
                  `Error executing statement from ${file}:`,
                  errorMessage
                )
                // å‹ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’å‡ºåŠ›
                if (error && typeof error === 'object' && 'query' in error) {
                  console.error(
                    'Failed query:',
                    (error as { query: string }).query
                  )
                }
                if (error && typeof error === 'object' && 'params' in error) {
                  console.error(
                    'params:',
                    (error as { params: unknown }).params
                  )
                }
              }
            }
          }
        } catch (error) {
          const errorMessage =
            error instanceof Error ? error.message : String(error)
          console.error(`Error processing migration ${file}:`, errorMessage)
        }
      }

      this.migrationsRun = true
      console.log('âœ… Migrations completed')
    } catch (error) {
      console.error('âŒ Migration failed:', error)
      throw error
    }
  }

  /**
   * ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆSequentialå®Ÿè¡Œç”¨ï¼‰
   */
  async createTransactionalContext(): Promise<TestContext> {
    await this.runMigrationsOnce()

    const connectionString = this.testEnv.getPostgresConnectionString()
    const testClient = postgres(connectionString, {
      onnotice: () => {},
      max: 1, // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ä½¿ç”¨æ™‚ã«å¿…è¦
    })
    const testDb = drizzle(testClient)

    // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
    await testClient`BEGIN`

    const cleanup = async () => {
      try {
        await testClient`ROLLBACK`
      } finally {
        await testClient.end()
      }
    }

    return { db: testDb, client: testClient, cleanup }
  }

  /**
   * ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ãƒ¼ãƒ–ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãªã—ï¼‰
   */
  async createCleanContext(): Promise<TestContext> {
    await this.runMigrationsOnce()

    const connectionString = this.testEnv.getPostgresConnectionString()
    const testClient = postgres(connectionString, {
      onnotice: () => {},
      max: 1, // ã‚·ãƒ³ã‚°ãƒ«æ¥ç¶š
    })
    const testDb = drizzle(testClient)

    // å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    await this.cleanAllTables(testDb)

    const cleanup = async () => {
      await testClient.end()
    }

    return { db: testDb, client: testClient, cleanup }
  }

  /**
   * ã‚¹ã‚­ãƒ¼ãƒåˆ†é›¢ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆParallelå®Ÿè¡Œç”¨ï¼‰
   */
  async createParallelContext(): Promise<ParallelTestContext> {
    await this.runMigrationsOnce()

    const schemaName = `test_${randomUUID().replace(/-/g, '_')}`

    // æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ
    await this.masterDb.execute(
      sql`CREATE SCHEMA ${sql.identifier(schemaName)}`
    )

    // publicã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰æ§‹é€ ã‚’ã‚³ãƒ”ãƒ¼
    await this.copySchemaStructure('public', schemaName)

    // ãƒ†ã‚¹ãƒˆç”¨ã®æ¥ç¶šã‚’ä½œæˆ
    const connectionString = this.testEnv.getPostgresConnectionString()
    const testClient = postgres(connectionString, {
      onnotice: () => {},
    })

    // search_pathã‚’è¨­å®š
    await testClient`SET search_path TO ${testClient(schemaName)}, public`

    const testDb = drizzle(testClient)

    this.activeSchemas.add(schemaName)

    const cleanup = async () => {
      try {
        await testClient.end()
        await this.masterDb.execute(
          sql`DROP SCHEMA ${sql.identifier(schemaName)} CASCADE`
        )
        this.activeSchemas.delete(schemaName)
      } catch (error) {
        console.error(`Failed to cleanup schema ${schemaName}:`, error)
      }
    }

    return { db: testDb, client: testClient, schemaName, cleanup }
  }

  private async copySchemaStructure(
    sourceSchema: string,
    targetSchema: string
  ): Promise<void> {
    const copyQuery = sql`
      DO $$
      DECLARE
        obj record;
        query text;
      BEGIN
        -- Copy tables
        FOR obj IN
          SELECT table_name
          FROM information_schema.tables
          WHERE table_schema = ${sourceSchema}
            AND table_type = 'BASE TABLE'
        LOOP
          query := format(
            'CREATE TABLE %I.%I (LIKE %I.%I INCLUDING ALL)',
            ${targetSchema}, obj.table_name, ${sourceSchema}, obj.table_name
          );
          EXECUTE query;
        END LOOP;
        
        -- Copy sequences
        FOR obj IN
          SELECT sequence_name
          FROM information_schema.sequences
          WHERE sequence_schema = ${sourceSchema}
        LOOP
          query := format(
            'CREATE SEQUENCE %I.%I START WITH 1',
            ${targetSchema}, obj.sequence_name
          );
          EXECUTE query;
        END LOOP;
      END $$;
    `

    await this.masterDb.execute(copyQuery)
  }

  private async cleanAllTables(db: PostgresJsDatabase): Promise<void> {
    // ä¾å­˜é–¢ä¿‚ã®é€†é †ã§å‰Šé™¤
    const tablesToClean = [
      // Authentication related tables (dependent on users)
      'user_sessions',
      'sessions',
      'password_reset_tokens',
      'email_verification_tokens',
      'user_2fa_secrets',
      'failed_login_attempts',
      'auth_audit_logs',
      'trusted_ip_addresses',

      // File related tables
      'download_logs',
      'share_links',
      'attachments',

      // Business tables (in dependency order)
      'reviews',
      'booking_reservations',
      'bookings',
      'reservations',
      'services',
      'service_categories',
      'staff_working_hours',
      'staff',
      'opening_hours',

      // Core tables
      'users',
      'customers',
      'salons',
    ]

    for (const table of tablesToClean) {
      try {
        await db.execute(sql`DELETE FROM ${sql.identifier(table)}`)
      } catch (_e) {
        // Table might not exist, ignore
      }
    }
  }

  async cleanup(): Promise<void> {
    // ã™ã¹ã¦ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for (const schemaName of this.activeSchemas) {
      try {
        await this.masterDb.execute(
          sql`DROP SCHEMA ${sql.identifier(schemaName)} CASCADE`
        )
      } catch (error) {
        console.error(`Failed to cleanup schema ${schemaName}:`, error)
      }
    }

    this.activeSchemas.clear()
    await this.masterClient.end()
  }
}

// ä¾¿åˆ©ãªãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
export async function createTestContext(): Promise<TestContext> {
  const setup = await TestDatabaseSetup.getInstance()
  return setup.createTransactionalContext()
}

export async function createCleanTestContext(): Promise<TestContext> {
  const setup = await TestDatabaseSetup.getInstance()
  return setup.createCleanContext()
}

export async function createParallelTestContext(): Promise<ParallelTestContext> {
  const setup = await TestDatabaseSetup.getInstance()
  return setup.createParallelContext()
}
